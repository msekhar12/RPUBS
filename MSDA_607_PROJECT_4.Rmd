---
title: "MsDA_607_Project_4"
author: "Sekhar Mekala"
date: "Sunday, April 19, 2015"
output: html_document
---

##Objective
The main objective of this project is to parse the blog entries present at the web site "http://www.r-bloggers.com/search/web%20scraping" (This web site contains the search results obtained when "web scraping" is searched at "http://www.r-bloggers.com". But we will write a generic R function to search any key word(s) at "r-bloggers.com" website).  

Specifically here are the requirements of this project:

1. Parse the first page blog entries present at "http://www.r-bloggers.com/search/web%20scraping" and output a data frame named first_page_df, with three variables: 
  **title, date and author**. Generalize this logic to any web page returned when a key word search is made at "http://www.r-bloggers.com""

2. Get the number of pages obtained as the search results in "http://www.r-bloggers.com/search/web%20scraping", parse each page of the search results, and build a data frame all_pages_df, with three variables: **title, date and author**. Generalize this logic to any web page returned when a key word search is made at "http://www.r-bloggers.com"

3. Generalize the program logic, and let the user enter a search string. The program should return the results in the form of a data frame with three variables: **title, date and author**


##Design
We will develop the following R functions to support the above objectives:
* scrape_html(url) 
This function takes a URL as input and outputs the data frame containing the blog's title, date (when the blog was posted) and the blog's author. 

* max_pages(html_txt)
This function takes HTML Text (obtained from www.r-bloggers.com, whenever a search is made at this web site), parses the text, and outputs the number of pages returned as search results

* search_Rbloggers(search_keywords)
This function takes character string as input, searches the text at www.r-bloggers.com website, and gives a data frame containing the blog's title, date (when the blog was posted) and the blog's author. This function calls the other two functions scrape_html() and max_pages()

##Required R packages
We need the following R packages:

* rvest

* data.frame

**NOTE:** We will use "selector gadget" to get the required HTML elements. For more information, visit "http://selectorgadget.com"


##Code Implementation
The following R Code creates a function named "scrape_html()". It takes a URL as input, gets the html page associated to the URL and obtains the "h2", ".meta" and ".date" HTML elements data. This function works correctly for the URL obtained whenever any keyword(s) search is made at www.r-bloggers.com website. If this code is used for any other website, you may see some unexpected results. In order to identify the "h2", ".meta", and ".date" elements, I opened the "www.r-bloggers.com/search/web%20scraping" in Google chrome, enabled the selector gadget, and selected and un-selected the required elements on the page. 

###The R code for "scrape_html()" function is given below:
```{r}

scrape_html <- function(url)
  {
library(rvest)
library(data.table)
  html_txt <- html(url)


#Gets the posts headings
title <- html_txt %>% 
  html_nodes("#leftcontent h2") %>%
  html_text()



#Gets the authors and date information
authors_and_post_date <- html_txt %>% 
  html_nodes(".meta , .date #leftcontent h2") %>%
  html_text()

temp_df <- data.frame(rbindlist(lapply(strsplit(authors_and_post_date,split="By "),as.list)))

names(temp_df) <- c("date","author")

#If the author's details are protected, the NA values will be displayed
  temp_df$author[grep("protected",as.vector(temp_df$author))] <- NA

page_df <- cbind(title,temp_df)


return(page_df)

  
  }


```


Let us call the scrape_html() function with "http://www.r-bloggers.com/search/web%20scraping" as input. This is the first page obtained when "web scraping" is searched at "www.r-bloggers.com". NOTE that we obtain a data frame as output, and this data frame contains the topic name, author and date details (only on the input page).

**NOTE:** This function call satisfies the **objective-1** of our project : "Parse the first page blog entries present at "http://www.r-bloggers.com/search/web%20scraping" and output a data frame named first_page_df, with three variables: **title, date and author**"

```{r}
#Calling the scrape_html function with "http://www.r-bloggers.com/search/web%20scraping" as input.

url <- "http://www.r-bloggers.com/search/web%20scraping"

first_page_df <- scrape_html(url)
first_page_df
```

**NOTE:** In the above function code, if any author's details are protected, then NA values are displayed in "author" variable


The above display shows the contents of first_page_df data frame. This data frame has three variables **title, date and author**.

###The R code for "max_pages()" function is given below:

The following R code gets the maximum number of pages returned for any search query at www.r-bloggers.com

**NOTE:** This function call satisfies the **objective-2** of our project : "Get the maximum number of pages returned whenever any key word search is made at www.r-bloggers.com"

```{r}
#This function takes HTML text as input and returns the maxium number of pages obtained by the search query at www.r-bloggers.com
max_pages <- function(html_txt)
  {
   #Gets the page numbers
p <- html_txt %>% 
  html_nodes(".pages") %>%
  html_text()
 
#Parsing p
return(as.numeric(strsplit(p,"of ")[[1]][2]))
  }

# calling the function

```



###The R code for "search_Rbloggers()" function is given below:
The R code to parse all the pages returned when any key word is searched, is given below. This function takes a search string as input and returns a data frame with three variables:**title, date and author**. A call to this function with "web scraping" as input returns all the search results of "web scraping", in the form of a data frame (with details: **title, date and author**)

```{r}

search_Rbloggers <- function(str)
  {
  
library(rvest)
library(data.table)

str <- gsub(" ", "%20", str)
 
url <- paste("http://www.r-bloggers.com/search/",str,sep="")

html_txt <- html(url)

#Parsing the first page ...
all_pages_df <- scrape_html(url)

#all_pages_df$page <- 1
#Getting the max number of pages
p <- max_pages(html_txt)

#Parsing the 2nd pasge to last pages
if (p > 1)
  {
for(i in 2:p)
  {
  
     url <- paste("http://www.r-bloggers.com/search/",str,"/page/",i,"/",sep="")
     all_pages_df <- rbind(all_pages_df,scrape_html(url))       
     
     #print(i)
     #print(scrape_html(url))
     
       
  
  }
}

return(all_pages_df)
}

```

Calling the search_Rbloggers() function with "web scraping" as input. You can call the function if you want to search any key word(s). 

**NOTE:** This function call satisfies the **objective-3** of our project : "Generalize the program logic, and let the user enter a search string. The program should return the results in the form of a data frame with three variables: **title, date and author**"


```{r}

df_temp <- search_Rbloggers("web scraping")
print(data.frame(df_temp),right=FALSE)
```

The above display shows the search results obtained by scraping all the pages of the search results (for the key word(s) "web scraping" at R-bloggers.com website).


##Calling the function search_Rbloggers() with "rvest" as key word search
```{r}

df_temp <- search_Rbloggers("rvest")
print(data.frame(df_temp),right=FALSE)

```

The above data frame display the search results of "rvest" key word at "r-bloggers.com"

You may use any desired key word(s) (enclosed in quotes), as input to search_Rbloggers() function.

##Summary
This project created a generic function which takes some key word(s) as input, searches the "www.r-bloggers.com" website and returns the search results in the form of a data frame with three variables: **title, date and author**. This function, if implemented in C++ or Java, can act as an API to the search the "www.r-bloggers.com" web site. The data frame returned by the function can be enhanced to include the URL and page number (to which the blog belongs to, in the search results).

<span style="color:blue; font-family:Georgia; font-size:2em;">
                                                         -~-End of Project Report-~- 
</span>                                    